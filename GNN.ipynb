{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd.variable import *\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import util\n",
    "from __future__ import print_function\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "save_path = '/bigdata/shared/HepSIM/np/'\n",
    "training = np.load(save_path + 'training1.npy')\n",
    "target = np.load(save_path + 'target1.npy')\n",
    "params = ['Px','Py', 'Pz', 'PT', 'E', 'D0', 'DZ', 'X', 'Y',  'Z', 'T', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import util\n",
    "N = 100\n",
    "df = util.h5_to_df(\"/bigdata/shared/HepSIM/combo/pythia8_higgs_2_combo.h5\")\n",
    "params = ['Px','Py', 'Pz', 'PT', 'E', 'D0', 'DZ', 'X', 'Y',  'Z', 'T', 'count']\n",
    "training, target = util.df_to_target(df, output = None, params = params, max_len = N)\n",
    "training = np.einsum('ijk->ikj', training)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, n_constituents, n_targets, params, hidden):\n",
    "        super(GraphNet, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        self.P = len(params)\n",
    "        self.N = n_constituents\n",
    "        self.Nr = self.N * (self.N - 1)\n",
    "        self.Dr = 0\n",
    "        self.De = 5\n",
    "        self.Dx = 0\n",
    "        self.Do = 6\n",
    "        self.n_targets = n_targets\n",
    "        self.assign_matrices()\n",
    "\n",
    "        self.Ra = Variable(torch.ones(self.Dr, self.Nr))\n",
    "        self.fr1 = nn.Linear(2 * self.P + self.Dr, hidden).cuda()\n",
    "        self.fr2 = nn.Linear(hidden, hidden/2).cuda()\n",
    "        self.fr3 = nn.Linear(hidden/2, self.De).cuda()\n",
    "        self.fo1 = nn.Linear(self.P + self.Dx + self.De, hidden).cuda()\n",
    "        self.fo2 = nn.Linear(hidden, hidden/2).cuda()\n",
    "        self.fo3 = nn.Linear(hidden/2, self.Do).cuda()\n",
    "        self.fc1 = nn.Linear(self.Do * self.N, hidden).cuda()\n",
    "        self.fc2 = nn.Linear(hidden, hidden/2).cuda()\n",
    "        self.fc3 = nn.Linear(hidden/2, self.n_targets).cuda()\n",
    "    \n",
    "    def assign_matrices(self):\n",
    "        self.Rr = torch.zeros(self.N, self.Nr)\n",
    "        self.Rs = torch.zeros(self.N, self.Nr)\n",
    "        receiver_sender_list = [i for i in itertools.product(range(self.N), range(self.N)) if i[0]!=i[1]]\n",
    "        for i, (r, s) in enumerate(receiver_sender_list):\n",
    "            self.Rr[r, i] = 1\n",
    "            self.Rs[s, i] = 1\n",
    "        self.Rr = Variable(self.Rr).cuda()\n",
    "        self.Rs = Variable(self.Rs).cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        Orr = self.tmul(x, self.Rr)\n",
    "        Ors = self.tmul(x, self.Rs)\n",
    "        B = torch.cat([Orr, Ors], 1)\n",
    "        ### First MLP ###\n",
    "        B = torch.transpose(B, 1, 2).contiguous()\n",
    "        B = nn.functional.relu(self.fr1(B.view(-1, 2 * self.P + self.Dr)))\n",
    "        B = nn.functional.relu(self.fr2(B))\n",
    "        E = nn.functional.relu(self.fr3(B).view(-1, self.Nr, self.De))\n",
    "        del B\n",
    "        E = torch.transpose(E, 1, 2).contiguous()\n",
    "        Ebar = self.tmul(E, torch.transpose(self.Rr, 0, 1).contiguous())\n",
    "        del E\n",
    "        C = torch.cat([x, Ebar], 1)\n",
    "        C = torch.transpose(C, 1, 2).contiguous()\n",
    "        ### Second MLP ###\n",
    "        C = nn.functional.relu(self.fo1(C.view(-1, self.P + self.Dx + self.De)))\n",
    "        C = nn.functional.relu(self.fo2(C))\n",
    "        O = nn.functional.relu(self.fo3(C).view(-1, self.N, self.Do))\n",
    "        del C\n",
    "        ### Classification MLP ###\n",
    "        N = nn.functional.relu(self.fc1(O.view(-1, self.Do * self.N)))\n",
    "        del O\n",
    "        N = nn.functional.relu(self.fc2(N))\n",
    "        N = nn.functional.relu(self.fc3(N))\n",
    "        return N\n",
    "\n",
    "    def tmul(self, x, y):  #Takes (I * J * K)(K * L) -> I * J * L \n",
    "        x_shape = x.size()\n",
    "        y_shape = y.size()\n",
    "        return torch.mm(x.view(-1, x_shape[2]), y).view(-1, x_shape[1], y_shape[1])\n",
    "    \n",
    "def get_sample(training, target, choice):\n",
    "    target_vals = np.argmax(target, axis = 1)\n",
    "    ind, = np.where(target_vals == choice)\n",
    "    chosen_ind = np.random.choice(ind, 50000)\n",
    "    return training[chosen_ind], target[chosen_ind]\n",
    "\n",
    "n_targets = target.shape[1]\n",
    "samples = [get_sample(training, target, i) for i in range(n_targets)]\n",
    "trainings = [i[0] for i in samples]\n",
    "targets = [i[1] for i in samples]\n",
    "big_training = np.concatenate(trainings)\n",
    "big_target = np.concatenate(targets)\n",
    "big_training, big_target = util.shuffle_together(big_training, big_target)\n",
    "\n",
    "val_split = 0.1\n",
    "batch_size = 1000\n",
    "n_epochs = 100\n",
    "\n",
    "trainingv = Variable(torch.FloatTensor(big_training))\n",
    "targetv = Variable(torch.from_numpy(np.argmax(big_target, axis = 1)).long())  \n",
    "trainingv, valv = torch.split(trainingv, int(trainingv.size()[0] * (1 - val_split)))\n",
    "targetv, val_targetv = torch.split(targetv, int(targetv.size()[0] * (1 - val_split)))\n",
    "gnn = GraphNet(N, n_targets, params, 10)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gnn.parameters())\n",
    "loss_vals = np.zeros(n_epochs)\n",
    "acc_vals = np.zeros(n_epochs)\n",
    "for i in range(n_epochs):\n",
    "    print(\"Epoch %s\" % i)\n",
    "    for j in range(0, trainingv.size()[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        out = gnn(trainingv[j:j + batch_size].cuda())\n",
    "        l = loss(out, targetv[j:j + batch_size].cuda())\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        loss_string = \"Loss: %s\" % \"{0:.5f}\".format(l.cpu().data.numpy()[0])\n",
    "        util.printProgressBar(j + batch_size, trainingv.size()[0], \n",
    "                              prefix = \"%s [%s/%s] \" % (loss_string, \n",
    "                                                       j + batch_size, \n",
    "                                                       trainingv.size()[0]),\n",
    "                              length = 20)\n",
    "    lst = []\n",
    "    for j in torch.split(valv, 100):\n",
    "        a = gnn(j.cuda()).cpu().data.numpy()\n",
    "        lst.append(a)\n",
    "    predicted = Variable(torch.FloatTensor(np.concatenate(lst)))\n",
    "    acc_vals[i] = stats(predicted, val_targetv)\n",
    "    loss_vals[i] = l.cpu().data.numpy()[0]\n",
    "    if all(loss_vals[max(0, i - 5):i] > min(np.append(loss_vals[0:max(0, i - 5)], 200))) and i > 5:\n",
    "        print(loss_vals, '\\n', np.diff(loss_vals))\n",
    "        break\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnn = GraphNet(3, 4, ['Px'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predict, target):\n",
    "    _, p_vals = torch.max(predict, 1)\n",
    "    r = torch.sum(target == p_vals.squeeze(1)).data.numpy()[0]\n",
    "    t = target.size()[0]\n",
    "    return r * 1.0 / t\n",
    "\n",
    "def stats(predict, target):\n",
    "    _, p_vals = torch.max(predict, 1)\n",
    "    t = target.cpu().data.numpy()\n",
    "    p_vals = p_vals.squeeze(1).data.numpy()\n",
    "    vals = np.unique(t)\n",
    "    for i in vals:\n",
    "        ind = np.where(t == i)\n",
    "        pv = p_vals[ind]\n",
    "        correct = sum(pv == t[ind])\n",
    "        print(\"  Target %s: %s/%s = %s%%\" % (i, correct, len(pv), correct * 100.0/len(pv)))\n",
    "    print(\"Overall: %s/%s = %s%%\" % (sum(p_vals == t), len(t), sum(p_vals == t) * 100.0/len(t)))\n",
    "    return sum(p_vals == t) * 100.0/len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n + 1)\n",
    "\n",
    "def predicted_histogram(data, \n",
    "                        target, \n",
    "                        labels = None, \n",
    "                        nbins = 10, \n",
    "                        out = None,\n",
    "                        xlabel = None,\n",
    "                        title = None\n",
    "                       ):\n",
    "    \"\"\"@params:\n",
    "        data = n x 1 array of parameter values\n",
    "        target = n x categories array of predictions\n",
    "    \"\"\"\n",
    "    target = preprocessing.normalize(target, norm = \"l1\")\n",
    "    if labels == None:\n",
    "        labels = [\"\" for i in range(target.shape[1])]\n",
    "    #1 decide bins\n",
    "    ma = np.amax(data) * 1.0\n",
    "    mi = np.amin(data)\n",
    "    bins = np.linspace(mi, ma, nbins)\n",
    "    bin_size = bins[1] - bins[0]\n",
    "    bin_locs = np.digitize(data, bins, right = True)\n",
    "    #2 set up bin x category matrix\n",
    "    #  Each M(bin, category) = Sum over particles with param in bin of category\n",
    "    M = np.array([np.sum(target[np.where(bin_locs == i)], axis = 0) \n",
    "                  for i in range(nbins)])\n",
    "    #3 plot each category/bin\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    bars = np.array([M[:, i] for i in range(M.shape[1])])\n",
    "    cmap = get_cmap(len(bars), 'viridis')\n",
    "    for i in range(len(bars)):\n",
    "        ax.bar(bins, bars[i], \n",
    "               bottom = sum(bars[:i]), \n",
    "               color = cmap(i), \n",
    "               label = labels[i],\n",
    "               width = bin_size\n",
    "              )\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "def generate_control_plots():\n",
    "    len_params = len(params)\n",
    "    path = '/bigdata/shared/HepSIM/img/n-h-hb/'\n",
    "    os.makedirs(path)\n",
    "    pred = gnn(valv)\n",
    "    d_target = np.array([util.get_list_from_num(i, length = n_targets) \n",
    "                             for i in val_targetv.cpu().data.numpy()])\n",
    "    p_target = pred.cpu().data.numpy()\n",
    "    for i in range(len(params)):\n",
    "        xlabel = params[i]\n",
    "        labels = [\"None\", \"H\", \"H + b\"]\n",
    "        data = np.mean(valv.data.numpy()[:, i, :], axis = 1)\n",
    "        predicted_histogram(data, d_target, \n",
    "                            nbins = 50, labels = labels,\n",
    "                            xlabel = xlabel, \n",
    "                            title = \"Actual Distribution\"\n",
    "                           )\n",
    "        plt.savefig(path + xlabel + \"-actual.png\", dpi = 200)\n",
    "        predicted_histogram(data, p_target, \n",
    "                            nbins = 50, labels = labels,\n",
    "                            xlabel = xlabel,\n",
    "                            title = \"Predicted Distribution\"\n",
    "                           )\n",
    "        plt.savefig(path + xlabel + \"-predicted.png\", dpi = 200)\n",
    "        plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "path = '/bigdata/shared/HepSIM/img/1ep-'\n",
    "display(Image(filename=path + 'Px-actual.png'))\n",
    "display(Image(filename=path + 'Px-predicted.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_control_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = '/bigdata/shared/HepSIM/np/'\n",
    "np.save(save_path + 'traininght.npy', training)\n",
    "np.save(save_path + 'targetht.npy', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.FloatTensor(np.concatenate(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.parents.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = util.h5_to_df(\"/bigdata/shared/HepSIM/combo/pythia8_higgs_2_combo.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df.parents.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.parents == \"['Z', 'b', 't']\"].njet.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(np.append(np.array([]), 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(5,5), dpi = 200)\n",
    "plt.plot(acc_vals[:45])\n",
    "sns.set()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary = \n",
    "Out[22]:\n",
    "array([ 72.5 ,  73.71,  75.01,  76.08,  78.39,  81.06,  83.22,  84.23,\n",
    "        85.14,  85.72,  86.04,  86.23,  86.24,  86.3 ,  86.27,  86.17,\n",
    "        86.58,  86.34,  86.47,  86.77,  86.73,  86.84,  86.66,  86.77,\n",
    "        86.72,  86.92,  86.84,  86.95,  86.9 ,  87.08,  87.1 ,  87.02,\n",
    "        86.91,  86.98,  87.21,  87.27,  87.45,  87.27,  87.51,  87.34,\n",
    "        87.44,  87.56,  87.69,  87.39,  87.65,  87.56,  87.67,  87.5 ,\n",
    "        87.67,  87.67,  87.79,  87.73,  87.87,  87.74,  87.7 ,  87.66,\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
