{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd.variable import *\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import util\n",
    "from __future__ import print_function\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "save_path = '/bigdata/shared/HepSIM/np/'\n",
    "training = np.load(save_path + 'training-100.npy')\n",
    "target = np.load(save_path + 'target.npy')\n",
    "params = ['Px','Py', 'Pz', 'PT', 'E', 'D0', 'DZ', 'X', 'Y',  'Z', 'T', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['codemirror/mode/clike/clike'], function(Clike) { console.log('ROOTaaS - C++ CodeMirror module loaded'); });"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to ROOTaaS 6.06/04\n",
      "reading file\n",
      "Generate dictionary\n",
      "['H', 'W+', 'Z', 'b', 'b', 'c', 'c'] 3\n",
      "['H', 'W+', 'Z', 'b', 'b', 'c'] 3\n",
      "['H', 'W+', 'Z', 'b', 'b', 's', 's'] 3\n",
      "['H', 'W+', 'Z', 'b', 'b', 's'] 3\n",
      "['H', 'W+', 'Z', 'b', 'b', 't'] 3\n",
      "['H', 'W+', 'Z', 'b', 'b'] 3\n",
      "['H', 'W+', 'Z', 'b'] 2\n",
      "['H', 'W+', 'Z', 'c', 'c'] 1\n",
      "['H', 'W+', 'Z', 'c'] 1\n",
      "['H', 'W+', 'Z', 's', 's'] 1\n",
      "['H', 'W+', 'Z', 's'] 1\n",
      "['H', 'W+', 'Z', 't'] 1\n",
      "['H', 'W+', 'Z'] 1\n",
      "['H', 'W+', 'b', 'b', 'c', 'c', 't'] 3\n",
      "['H', 'W+', 'b', 'b', 'c', 'c'] 3\n",
      "['H', 'W+', 'b', 'b', 'c', 's'] 3\n",
      "['H', 'W+', 'b', 'b', 'c', 't'] 3\n",
      "['H', 'W+', 'b', 'b', 'c'] 3\n",
      "['H', 'W+', 'b', 'b', 's', 's', 't'] 3\n",
      "['H', 'W+', 'b', 'b', 's', 's'] 3\n",
      "['H', 'W+', 'b', 'b', 's', 't'] 3\n",
      "['H', 'W+', 'b', 'b', 's'] 3\n",
      "['H', 'W+', 'b', 'b', 't'] 3\n",
      "['H', 'W+', 'b', 'b'] 3\n",
      "['H', 'W+', 'b', 't'] 2\n",
      "['H', 'W+', 'b'] 2\n",
      "['H', 'W+', 'c', 'c', 's', 's'] 1\n",
      "['H', 'W+', 'c', 'c', 's'] 1\n",
      "['H', 'W+', 'c', 'c'] 1\n",
      "['H', 'W+', 'c', 's', 's'] 1\n",
      "['H', 'W+', 'c', 's'] 1\n",
      "['H', 'W+', 'c'] 1\n",
      "['H', 'W+', 's', 's'] 1\n",
      "['H', 'W+', 's'] 1\n",
      "['H', 'W+', 't'] 1\n",
      "['H', 'W+'] 1\n",
      "['H', 'Z', 'b', 'b', 'c', 'c'] 3\n",
      "['H', 'Z', 'b', 'b', 'c', 's', 's'] 3\n",
      "['H', 'Z', 'b', 'b', 'c', 's'] 3\n",
      "['H', 'Z', 'b', 'b', 'c'] 3\n",
      "['H', 'Z', 'b', 'b', 's', 's'] 3\n",
      "['H', 'Z', 'b', 'b', 's'] 3\n",
      "['H', 'Z', 'b', 'b', 't'] 3\n",
      "['H', 'Z', 'b', 'b'] 3\n",
      "['H', 'Z', 'b', 'c', 'c'] 2\n",
      "['H', 'Z', 'b', 'c', 's'] 2\n",
      "['H', 'Z', 'b', 'c'] 2\n",
      "['H', 'Z', 'b', 's', 's'] 2\n",
      "['H', 'Z', 'b', 's'] 2\n",
      "['H', 'Z', 'b', 't'] 2\n",
      "['H', 'Z', 'b'] 2\n",
      "['H', 'Z', 'c', 'c'] 1\n",
      "['H', 'Z', 'c', 's'] 1\n",
      "['H', 'Z', 'c'] 1\n",
      "['H', 'Z', 's', 's'] 1\n",
      "['H', 'Z', 's'] 1\n",
      "['H', 'Z'] 1\n",
      "['H', 'b', 'b', 'c', 'c', 's', 's'] 3\n",
      "['H', 'b', 'b', 'c', 'c', 's'] 3\n",
      "['H', 'b', 'b', 'c', 'c'] 3\n",
      "['H', 'b', 'b', 'c', 's', 's'] 3\n",
      "['H', 'b', 'b', 'c', 's'] 3\n",
      "['H', 'b', 'b', 'c'] 3\n",
      "['H', 'b', 'b', 's', 's'] 3\n",
      "['H', 'b', 'b', 's'] 3\n",
      "['H', 'b', 'b', 't'] 3\n",
      "['H', 'b', 'b'] 3\n",
      "['H', 'b', 'c', 'c'] 2\n",
      "['H', 'b', 'c', 's'] 2\n",
      "['H', 'b', 'c'] 2\n",
      "['H', 'b', 's', 's'] 2\n",
      "['H', 'b', 's'] 2\n",
      "['H', 'b', 't'] 2\n",
      "['H', 'b'] 2\n",
      "['H', 'c', 'c', 's', 's'] 1\n",
      "['H', 'c', 'c', 's'] 1\n",
      "['H', 'c', 'c'] 1\n",
      "['H', 'c', 's', 's'] 1\n",
      "['H', 'c', 's'] 1\n",
      "['H', 'c'] 1\n",
      "['H', 's', 's'] 1\n",
      "['H', 's'] 1\n",
      "['H', 't'] 1\n",
      "['H'] 1\n",
      "['W+', 'Z', 'b', 'b', 'c', 'c', 's', 's'] 0\n",
      "['W+', 'Z', 'b', 'b', 'c', 'c', 's'] 0\n",
      "['W+', 'Z', 'b', 'b', 'c', 'c'] 0\n",
      "['W+', 'Z', 'b', 'b', 'c', 's', 's'] 0\n",
      "['W+', 'Z', 'b', 'b', 'c', 's'] 0\n",
      "['W+', 'Z', 'b', 'b', 'c'] 0\n",
      "['W+', 'Z', 'b', 'b', 's', 's', 't'] 0\n",
      "['W+', 'Z', 'b', 'b', 's', 's'] 0\n",
      "['W+', 'Z', 'b', 'b', 's'] 0\n",
      "['W+', 'Z', 'b', 'b', 't'] 0\n",
      "['W+', 'Z', 'b', 'b'] 0\n",
      "['W+', 'Z', 'b', 'c', 'c', 's', 's'] 0\n",
      "['W+', 'Z', 'b', 'c', 'c', 's', 't'] 0\n",
      "['W+', 'Z', 'b', 'c', 'c', 's'] 0\n",
      "['W+', 'Z', 'b', 'c', 'c', 't'] 0\n",
      "['W+', 'Z', 'b', 'c', 'c'] 0\n",
      "['W+', 'Z', 'b', 'c', 's', 's'] 0\n",
      "['W+', 'Z', 'b', 'c', 's'] 0\n",
      "['W+', 'Z', 'b', 'c'] 0\n",
      "['W+', 'Z', 'b', 's', 's'] 0\n",
      "['W+', 'Z', 'b', 's', 't'] 0\n",
      "['W+', 'Z', 'b', 's'] 0\n",
      "['W+', 'Z', 'b'] 0\n",
      "['W+', 'Z', 'c', 'c', 's', 's'] 0\n",
      "['W+', 'Z', 'c', 'c', 's'] 0\n",
      "['W+', 'Z', 'c', 'c'] 0\n",
      "['W+', 'Z', 'c', 's', 's'] 0\n",
      "['W+', 'Z', 's', 's'] 0\n",
      "['W+', 'Z', 's'] 0\n",
      "['W+', 'Z'] 0\n",
      "['W+', 'b', 'b', 'c', 'c', 't'] 0\n",
      "['W+', 'b', 'b', 'c', 't'] 0\n",
      "['W+', 'b', 'b', 's', 's', 't'] 0\n",
      "['W+', 'b', 'b', 's', 't'] 0\n",
      "['W+', 'b', 'b', 's'] 0\n",
      "['W+', 'b', 'b', 't'] 0\n",
      "['W+', 'b', 'b'] 0\n",
      "['W+', 'b', 'c', 's', 's'] 0\n",
      "['W+', 'b', 's', 's', 't'] 0\n",
      "['W+', 'b', 't'] 0\n",
      "['W+', 'b'] 0\n",
      "['W+', 's', 's'] 0\n",
      "['W+', 's'] 0\n",
      "['W+', 't'] 0\n",
      "['W+'] 0\n",
      "['Z', 'b', 'b', 'c', 'c', 's', 's'] 0\n",
      "['Z', 'b', 'b', 'c', 'c', 's'] 0\n",
      "['Z', 'b', 'b', 'c', 'c'] 0\n",
      "['Z', 'b', 'b', 'c', 's', 's'] 0\n",
      "['Z', 'b', 'b', 'c'] 0\n",
      "['Z', 'b', 'b', 's', 's'] 0\n",
      "['Z', 'b', 'b', 's'] 0\n",
      "['Z', 'b', 'b', 't'] 0\n",
      "['Z', 'b', 'b'] 0\n",
      "['Z', 'b', 'c', 's', 's'] 0\n",
      "['Z', 'b', 'c'] 0\n",
      "['Z', 'b', 's', 's'] 0\n",
      "['Z', 'b', 't'] 0\n",
      "['Z', 'b'] 0\n",
      "['Z', 's', 's'] 0\n",
      "['Z'] 0\n",
      "['b', 'b', 'c'] 0\n",
      "['b', 'b', 's', 's'] 0\n",
      "['b', 'b', 's', 't'] 0\n",
      "['b', 'b', 's'] 0\n",
      "['b', 'b', 't'] 0\n",
      "['b', 'b'] 0\n",
      "['b', 't'] 0\n",
      "['b'] 0\n",
      "['t'] 0\n",
      "Assigning jet_type...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "util.py:359: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  l = np.zeros(length)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1490621, 12, 100)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in <TUnixSystem::FindDynamicLibrary>: libDelphes[.so | .dll | .dylib | .sl | .dl | .a] does not exist in /usr/local/root/lib:/home/avikar/promc/promc/lib:/home/avikar/promc/promc/lib:/usr/local/cuda/targets/x86_64-linux/lib/:.:/usr/local/root/lib:/lib/x86_64-linux-gnu/tls/x86_64:/lib/x86_64-linux-gnu/tls:/lib/x86_64-linux-gnu/x86_64:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu/tls/x86_64:/usr/lib/x86_64-linux-gnu/tls:/usr/lib/x86_64-linux-gnu/x86_64:/usr/lib/x86_64-linux-gnu:/lib/tls/x86_64:/lib/tls:/lib/x86_64:/lib:/usr/lib/tls/x86_64:/usr/lib/tls:/usr/lib/x86_64:/usr/lib\r\n",
      "input_line_34:1:10: fatal error: 'classes/DelphesClasses.h' file not found\r\n",
      "#include \"classes/DelphesClasses.h\"\r\n",
      "         ^\r\n",
      "input_line_35:1:10: fatal error: 'external/ExRootAnalysis/ExRootTreeReader.h' file not found\r\n",
      "#include \"external/ExRootAnalysis/ExRootTreeReader.h\"\r\n",
      "         ^\r\n",
      "input_line_36:1:10: fatal error: 'external/ExRootAnalysis/ExRootResult.h' file not found\r\n",
      "#include \"external/ExRootAnalysis/ExRootResult.h\"\r\n",
      "         ^\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import util\n",
    "N = 100\n",
    "df = util.h5_to_df(\"/bigdata/shared/HepSIM/combo/pythia8_higgs_2_combo.h5\")\n",
    "params = ['Px','Py', 'Pz', 'PT', 'E', 'D0', 'DZ', 'X', 'Y',  'Z', 'T', 'count']\n",
    "training, target = util.df_to_target(df, output = None, params = params, max_len = N)\n",
    "training = np.einsum('ijk->ikj', training)\n",
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Loss: 1.22701 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 2395/4919 = 48.6887578776%\n",
      "  Target 1: 3073/5054 = 60.8033240997%\n",
      "  Target 2: 1921/5005 = 38.3816183816%\n",
      "  Target 3: 1058/5022 = 21.067303863%\n",
      "Overall: 8447/20000 = 42.235%\n",
      "Epoch 1\n",
      "Loss: 1.16461 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 2624/4919 = 53.3441756455%\n",
      "  Target 1: 3093/5054 = 61.1990502572%\n",
      "  Target 2: 2311/5005 = 46.1738261738%\n",
      "  Target 3: 893/5022 = 17.7817602549%\n",
      "Overall: 8921/20000 = 44.605%\n",
      "Epoch 2\n",
      "Loss: 1.12665 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 2782/4919 = 56.5562106119%\n",
      "  Target 1: 3683/5054 = 72.8729719034%\n",
      "  Target 2: 1603/5005 = 32.027972028%\n",
      "  Target 3: 1291/5022 = 25.7068896854%\n",
      "Overall: 9359/20000 = 46.795%\n",
      "Epoch 3\n",
      "Loss: 1.10262 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 2779/4919 = 56.4952226062%\n",
      "  Target 1: 3667/5054 = 72.5563909774%\n",
      "  Target 2: 1625/5005 = 32.4675324675%\n",
      "  Target 3: 1327/5022 = 26.4237355635%\n",
      "Overall: 9398/20000 = 46.99%\n",
      "Epoch 4\n",
      "Loss: 1.08985 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3149/4919 = 64.0170766416%\n",
      "  Target 1: 3533/5054 = 69.9050257222%\n",
      "  Target 2: 1823/5005 = 36.4235764236%\n",
      "  Target 3: 1114/5022 = 22.1823974512%\n",
      "Overall: 9619/20000 = 48.095%\n",
      "Epoch 5\n",
      "Loss: 1.07303 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3427/4919 = 69.6686318357%\n",
      "  Target 1: 3401/5054 = 67.2932330827%\n",
      "  Target 2: 1496/5005 = 29.8901098901%\n",
      "  Target 3: 1468/5022 = 29.2313819196%\n",
      "Overall: 9792/20000 = 48.96%\n",
      "Epoch 6\n",
      "Loss: 1.06169 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3256/4919 = 66.1923155113%\n",
      "  Target 1: 3690/5054 = 73.0114760586%\n",
      "  Target 2: 1482/5005 = 29.6103896104%\n",
      "  Target 3: 1487/5022 = 29.6097172441%\n",
      "Overall: 9915/20000 = 49.575%\n",
      "Epoch 7\n",
      "Loss: 1.05634 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3247/4919 = 66.0093514942%\n",
      "  Target 1: 3805/5054 = 75.2869014642%\n",
      "  Target 2: 1372/5005 = 27.4125874126%\n",
      "  Target 3: 1501/5022 = 29.8884906412%\n",
      "Overall: 9925/20000 = 49.625%\n",
      "Epoch 8\n",
      "Loss: 1.05065 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3443/4919 = 69.9939011994%\n",
      "  Target 1: 3708/5054 = 73.3676296003%\n",
      "  Target 2: 1364/5005 = 27.2527472527%\n",
      "  Target 3: 1540/5022 = 30.6650736758%\n",
      "Overall: 10055/20000 = 50.275%\n",
      "Epoch 9\n",
      "Loss: 1.04736 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3639/4919 = 73.9784509047%\n",
      "  Target 1: 3606/5054 = 71.3494261971%\n",
      "  Target 2: 1377/5005 = 27.5124875125%\n",
      "  Target 3: 1500/5022 = 29.8685782557%\n",
      "Overall: 10122/20000 = 50.61%\n",
      "Epoch 10\n",
      "Loss: 1.04095 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3583/4919 = 72.8400081317%\n",
      "  Target 1: 3693/5054 = 73.0708349822%\n",
      "  Target 2: 1601/5005 = 31.988011988%\n",
      "  Target 3: 1303/5022 = 25.9458383114%\n",
      "Overall: 10180/20000 = 50.9%\n",
      "Epoch 11\n",
      "Loss: 1.03356 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3641/4919 = 74.0191095751%\n",
      "  Target 1: 3667/5054 = 72.5563909774%\n",
      "  Target 2: 1483/5005 = 29.6303696304%\n",
      "  Target 3: 1396/5022 = 27.7976901633%\n",
      "Overall: 10187/20000 = 50.935%\n",
      "Epoch 12\n",
      "Loss: 1.02796 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3612/4919 = 73.4295588534%\n",
      "  Target 1: 3782/5054 = 74.8318163831%\n",
      "  Target 2: 1359/5005 = 27.1528471528%\n",
      "  Target 3: 1432/5022 = 28.5145360414%\n",
      "Overall: 10185/20000 = 50.925%\n",
      "Epoch 13\n",
      "Loss: 1.02448 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3640/4919 = 73.9987802399%\n",
      "  Target 1: 3826/5054 = 75.7024139296%\n",
      "  Target 2: 1490/5005 = 29.7702297702%\n",
      "  Target 3: 1323/5022 = 26.3440860215%\n",
      "Overall: 10279/20000 = 51.395%\n",
      "Epoch 14\n",
      "Loss: 1.01688 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3633/4919 = 73.8564748933%\n",
      "  Target 1: 3961/5054 = 78.3735654927%\n",
      "  Target 2: 1551/5005 = 30.989010989%\n",
      "  Target 3: 1192/5022 = 23.7355635205%\n",
      "Overall: 10337/20000 = 51.685%\n",
      "Epoch 15\n",
      "Loss: 1.01641 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3546/4919 = 72.0878227282%\n",
      "  Target 1: 4023/5054 = 79.6003165809%\n",
      "  Target 2: 1569/5005 = 31.3486513487%\n",
      "  Target 3: 1206/5022 = 24.0143369176%\n",
      "Overall: 10344/20000 = 51.72%\n",
      "Epoch 16\n",
      "Loss: 1.01493 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3619/4919 = 73.5718642%\n",
      "  Target 1: 3906/5054 = 77.2853185596%\n",
      "  Target 2: 1658/5005 = 33.1268731269%\n",
      "  Target 3: 1147/5022 = 22.8395061728%\n",
      "Overall: 10330/20000 = 51.65%\n",
      "Epoch 17\n",
      "Loss: 1.01835 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3533/4919 = 71.8235413702%\n",
      "  Target 1: 4053/5054 = 80.1939058172%\n",
      "  Target 2: 1506/5005 = 30.0899100899%\n",
      "  Target 3: 1222/5022 = 24.3329350856%\n",
      "Overall: 10314/20000 = 51.57%\n",
      "Epoch 18\n",
      "Loss: 1.01391 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3664/4919 = 74.4866842854%\n",
      "  Target 1: 3921/5054 = 77.5821131777%\n",
      "  Target 2: 1532/5005 = 30.6093906094%\n",
      "  Target 3: 1262/5022 = 25.1294305058%\n",
      "Overall: 10379/20000 = 51.895%\n",
      "Epoch 19\n",
      "Loss: 1.01410 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3650/4919 = 74.2020735922%\n",
      "  Target 1: 3978/5054 = 78.7099327266%\n",
      "  Target 2: 1512/5005 = 30.2097902098%\n",
      "  Target 3: 1246/5022 = 24.8108323377%\n",
      "Overall: 10386/20000 = 51.93%\n",
      "Epoch 20\n",
      "Loss: 1.02075 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3596/4919 = 73.1042894897%\n",
      "  Target 1: 3896/5054 = 77.0874554808%\n",
      "  Target 2: 1653/5005 = 33.026973027%\n",
      "  Target 3: 1205/5022 = 23.9944245321%\n",
      "Overall: 10350/20000 = 51.75%\n",
      "Epoch 21\n",
      "Loss: 1.00978 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3528/4919 = 71.721894694%\n",
      "  Target 1: 3959/5054 = 78.3339928769%\n",
      "  Target 2: 1649/5005 = 32.9470529471%\n",
      "  Target 3: 1222/5022 = 24.3329350856%\n",
      "Overall: 10358/20000 = 51.79%\n",
      "Epoch 22\n",
      "Loss: 1.00203 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3712/4919 = 75.4624923765%\n",
      "  Target 1: 3946/5054 = 78.0767708746%\n",
      "  Target 2: 1511/5005 = 30.1898101898%\n",
      "  Target 3: 1264/5022 = 25.1692552768%\n",
      "Overall: 10433/20000 = 52.165%\n",
      "Epoch 23\n",
      "Loss: 1.00165 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3728/4919 = 75.7877617402%\n",
      "  Target 1: 3992/5054 = 78.9869410368%\n",
      "  Target 2: 1456/5005 = 29.0909090909%\n",
      "  Target 3: 1281/5022 = 25.5077658303%\n",
      "Overall: 10457/20000 = 52.285%\n",
      "Epoch 24\n",
      "Loss: 0.99868 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3515/4919 = 71.457613336%\n",
      "  Target 1: 4175/5054 = 82.6078353779%\n",
      "  Target 2: 1347/5005 = 26.9130869131%\n",
      "  Target 3: 1343/5022 = 26.7423337316%\n",
      "Overall: 10380/20000 = 51.9%\n",
      "Epoch 25\n",
      "Loss: 0.99816 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3670/4919 = 74.6086602968%\n",
      "  Target 1: 4068/5054 = 80.4907004353%\n",
      "  Target 2: 1409/5005 = 28.1518481518%\n",
      "  Target 3: 1327/5022 = 26.4237355635%\n",
      "Overall: 10474/20000 = 52.37%\n",
      "Epoch 26\n",
      "Loss: 0.99531 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3679/4919 = 74.7916243139%\n",
      "  Target 1: 3998/5054 = 79.1056588841%\n",
      "  Target 2: 1511/5005 = 30.1898101898%\n",
      "  Target 3: 1296/5022 = 25.8064516129%\n",
      "Overall: 10484/20000 = 52.42%\n",
      "Epoch 27\n",
      "Loss: 0.99739 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3615/4919 = 73.4905468591%\n",
      "  Target 1: 4069/5054 = 80.5104867432%\n",
      "  Target 2: 1536/5005 = 30.6893106893%\n",
      "  Target 3: 1270/5022 = 25.2887295898%\n",
      "Overall: 10490/20000 = 52.45%\n",
      "Epoch 28\n",
      "Loss: 0.99404 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3744/4919 = 76.1130311039%\n",
      "  Target 1: 4001/5054 = 79.1650178077%\n",
      "  Target 2: 1471/5005 = 29.3906093906%\n",
      "  Target 3: 1310/5022 = 26.08522501%\n",
      "Overall: 10526/20000 = 52.63%\n",
      "Epoch 29\n",
      "Loss: 0.99130 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3797/4919 = 77.1904858711%\n",
      "  Target 1: 3910/5054 = 77.3644637911%\n",
      "  Target 2: 1430/5005 = 28.5714285714%\n",
      "  Target 3: 1356/5022 = 27.0011947431%\n",
      "Overall: 10493/20000 = 52.465%\n",
      "Epoch 30\n",
      "Loss: 0.98917 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3674/4919 = 74.6899776377%\n",
      "  Target 1: 4078/5054 = 80.688563514%\n",
      "  Target 2: 1487/5005 = 29.7102897103%\n",
      "  Target 3: 1269/5022 = 25.2688172043%\n",
      "Overall: 10508/20000 = 52.54%\n",
      "Epoch 31\n",
      "Loss: 1.00321 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3730/4919 = 75.8284204107%\n",
      "  Target 1: 3993/5054 = 79.0067273447%\n",
      "  Target 2: 1352/5005 = 27.012987013%\n",
      "  Target 3: 1463/5022 = 29.131819992%\n",
      "Overall: 10538/20000 = 52.69%\n",
      "Epoch 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.98528 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3693/4919 = 75.0762350071%\n",
      "  Target 1: 4114/5054 = 81.4008705975%\n",
      "  Target 2: 1510/5005 = 30.1698301698%\n",
      "  Target 3: 1216/5022 = 24.2134607726%\n",
      "Overall: 10533/20000 = 52.665%\n",
      "Epoch 33\n",
      "Loss: 0.98426 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3670/4919 = 74.6086602968%\n",
      "  Target 1: 4125/5054 = 81.6185199842%\n",
      "  Target 2: 1535/5005 = 30.6693306693%\n",
      "  Target 3: 1219/5022 = 24.2731979291%\n",
      "Overall: 10549/20000 = 52.745%\n",
      "Epoch 34\n",
      "Loss: 0.98349 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3700/4919 = 75.2185403537%\n",
      "  Target 1: 4069/5054 = 80.5104867432%\n",
      "  Target 2: 1602/5005 = 32.007992008%\n",
      "  Target 3: 1149/5022 = 22.8793309438%\n",
      "Overall: 10520/20000 = 52.6%\n",
      "Epoch 35\n",
      "Loss: 0.99296 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3694/4919 = 75.0965643423%\n",
      "  Target 1: 4131/5054 = 81.7372378314%\n",
      "  Target 2: 1539/5005 = 30.7492507493%\n",
      "  Target 3: 1160/5022 = 23.0983671844%\n",
      "Overall: 10524/20000 = 52.62%\n",
      "Epoch 36\n",
      "Loss: 0.98383 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3664/4919 = 74.4866842854%\n",
      "  Target 1: 4184/5054 = 82.7859121488%\n",
      "  Target 2: 1521/5005 = 30.3896103896%\n",
      "  Target 3: 1211/5022 = 24.1138988451%\n",
      "Overall: 10580/20000 = 52.9%\n",
      "Epoch 37\n",
      "Loss: 0.98163 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3642/4919 = 74.0394389103%\n",
      "  Target 1: 4135/5054 = 81.8163830629%\n",
      "  Target 2: 1572/5005 = 31.4085914086%\n",
      "  Target 3: 1202/5022 = 23.9346873755%\n",
      "Overall: 10551/20000 = 52.755%\n",
      "Epoch 38\n",
      "Loss: 0.98553 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3681/4919 = 74.8322829843%\n",
      "  Target 1: 4144/5054 = 81.9944598338%\n",
      "  Target 2: 1559/5005 = 31.1488511489%\n",
      "  Target 3: 1217/5022 = 24.2333731581%\n",
      "Overall: 10601/20000 = 53.005%\n",
      "Epoch 39\n",
      "Loss: 0.98245 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3680/4919 = 74.8119536491%\n",
      "  Target 1: 4164/5054 = 82.3901859913%\n",
      "  Target 2: 1579/5005 = 31.5484515485%\n",
      "  Target 3: 1199/5022 = 23.874950219%\n",
      "Overall: 10622/20000 = 53.11%\n",
      "Epoch 40\n",
      "Loss: 0.98302 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3730/4919 = 75.8284204107%\n",
      "  Target 1: 4137/5054 = 81.8559556787%\n",
      "  Target 2: 1575/5005 = 31.4685314685%\n",
      "  Target 3: 1193/5022 = 23.755475906%\n",
      "Overall: 10635/20000 = 53.175%\n",
      "Epoch 41\n",
      "Loss: 0.98251 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3715/4919 = 75.5234803822%\n",
      "  Target 1: 4064/5054 = 80.4115552038%\n",
      "  Target 2: 1609/5005 = 32.1478521479%\n",
      "  Target 3: 1180/5022 = 23.4966148945%\n",
      "Overall: 10568/20000 = 52.84%\n",
      "Epoch 42\n",
      "Loss: 0.98270 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3732/4919 = 75.8690790811%\n",
      "  Target 1: 4117/5054 = 81.4602295212%\n",
      "  Target 2: 1514/5005 = 30.2497502498%\n",
      "  Target 3: 1259/5022 = 25.0696933493%\n",
      "Overall: 10622/20000 = 53.11%\n",
      "Epoch 43\n",
      "Loss: 0.99165 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3833/4919 = 77.9223419394%\n",
      "  Target 1: 4094/5054 = 81.00514444%\n",
      "  Target 2: 1480/5005 = 29.5704295704%\n",
      "  Target 3: 1232/5022 = 24.5320589407%\n",
      "Overall: 10639/20000 = 53.195%\n",
      "Epoch 44\n",
      "Loss: 0.98353 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3731/4919 = 75.8487497459%\n",
      "  Target 1: 4130/5054 = 81.7174515235%\n",
      "  Target 2: 1590/5005 = 31.7682317682%\n",
      "  Target 3: 1193/5022 = 23.755475906%\n",
      "Overall: 10644/20000 = 53.22%\n",
      "Epoch 45\n",
      "Loss: 0.98056 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3702/4919 = 75.2591990242%\n",
      "  Target 1: 4135/5054 = 81.8163830629%\n",
      "  Target 2: 1593/5005 = 31.8281718282%\n",
      "  Target 3: 1202/5022 = 23.9346873755%\n",
      "Overall: 10632/20000 = 53.16%\n",
      "Epoch 46\n",
      "Loss: 0.97970 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3714/4919 = 75.503151047%\n",
      "  Target 1: 4106/5054 = 81.2425801345%\n",
      "  Target 2: 1538/5005 = 30.7292707293%\n",
      "  Target 3: 1269/5022 = 25.2688172043%\n",
      "Overall: 10627/20000 = 53.135%\n",
      "Epoch 47\n",
      "Loss: 0.98378 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3733/4919 = 75.8894084163%\n",
      "  Target 1: 4087/5054 = 80.8666402849%\n",
      "  Target 2: 1545/5005 = 30.8691308691%\n",
      "  Target 3: 1273/5022 = 25.3484667463%\n",
      "Overall: 10638/20000 = 53.19%\n",
      "Epoch 48\n",
      "Loss: 0.99574 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3893/4919 = 79.1421020533%\n",
      "  Target 1: 4037/5054 = 79.8773248912%\n",
      "  Target 2: 1276/5005 = 25.4945054945%\n",
      "  Target 3: 1495/5022 = 29.7690163282%\n",
      "Overall: 10701/20000 = 53.505%\n",
      "Epoch 49\n",
      "Loss: 0.98220 [180000/180000]  |####################| 100.0% \n",
      "  Target 0: 3791/4919 = 77.0685098597%\n",
      "  Target 1: 4046/5054 = 80.055401662%\n",
      "  Target 2: 1482/5005 = 29.6103896104%\n",
      "  Target 3: 1367/5022 = 27.2202309837%\n",
      "Overall: 10686/20000 = 53.43%\n",
      "Epoch 50\n",
      "Loss: 1.01404 [153000/180000]  |#################---| 85.0% "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-2bc56cc638fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainingv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-2bc56cc638fc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mEbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEbar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m### Second MLP ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mcat\u001b[0;34m(iterable, dim)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mConcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/_functions/tensor.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, n_constituents, n_targets, params, hidden):\n",
    "        super(GraphNet, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        self.P = len(params)\n",
    "        self.N = n_constituents\n",
    "        self.Nr = self.N * (self.N - 1)\n",
    "        self.Dr = 0\n",
    "        self.De = 5\n",
    "        self.Dx = 0\n",
    "        self.Do = 6\n",
    "        self.n_targets = n_targets\n",
    "        self.assign_matrices()\n",
    "\n",
    "        self.Ra = Variable(torch.ones(self.Dr, self.Nr))\n",
    "        self.fr1 = nn.Linear(2 * self.P + self.Dr, hidden).cuda()\n",
    "        self.fr2 = nn.Linear(hidden, hidden/2).cuda()\n",
    "        self.fr3 = nn.Linear(hidden/2, self.De).cuda()\n",
    "        self.fo1 = nn.Linear(self.P + self.Dx + self.De, hidden).cuda()\n",
    "        self.fo2 = nn.Linear(hidden, hidden/2).cuda()\n",
    "        self.fo3 = nn.Linear(hidden/2, self.Do).cuda()\n",
    "        self.fc1 = nn.Linear(self.Do * self.N, hidden).cuda()\n",
    "        self.fc2 = nn.Linear(hidden, hidden/2).cuda()\n",
    "        self.fc3 = nn.Linear(hidden/2, self.n_targets).cuda()\n",
    "    \n",
    "    def assign_matrices(self):\n",
    "        self.Rr = torch.zeros(self.N, self.Nr)\n",
    "        self.Rs = torch.zeros(self.N, self.Nr)\n",
    "        receiver_sender_list = [i for i in itertools.product(range(self.N), range(self.N)) if i[0]!=i[1]]\n",
    "        for i, (r, s) in enumerate(receiver_sender_list):\n",
    "            self.Rr[r, i] = 1\n",
    "            self.Rs[s, i] = 1\n",
    "        self.Rr = Variable(self.Rr).cuda()\n",
    "        self.Rs = Variable(self.Rs).cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        Orr = self.tmul(x, self.Rr)\n",
    "        Ors = self.tmul(x, self.Rs)\n",
    "        B = torch.cat([Orr, Ors], 1)\n",
    "        ### First MLP ###\n",
    "        B = torch.transpose(B, 1, 2).contiguous()\n",
    "        B = nn.functional.relu(self.fr1(B.view(-1, 2 * self.P + self.Dr)))\n",
    "        B = nn.functional.relu(self.fr2(B))\n",
    "        E = nn.functional.relu(self.fr3(B).view(-1, self.Nr, self.De))\n",
    "        del B\n",
    "        E = torch.transpose(E, 1, 2).contiguous()\n",
    "        Ebar = self.tmul(E, torch.transpose(self.Rr, 0, 1).contiguous())\n",
    "        del E\n",
    "        C = torch.cat([x, Ebar], 1)\n",
    "        C = torch.transpose(C, 1, 2).contiguous()\n",
    "        ### Second MLP ###\n",
    "        C = nn.functional.relu(self.fo1(C.view(-1, self.P + self.Dx + self.De)))\n",
    "        C = nn.functional.relu(self.fo2(C))\n",
    "        O = nn.functional.relu(self.fo3(C).view(-1, self.N, self.Do))\n",
    "        del C\n",
    "        ### Classification MLP ###\n",
    "        N = nn.functional.relu(self.fc1(O.view(-1, self.Do * self.N)))\n",
    "        del O\n",
    "        N = nn.functional.relu(self.fc2(N))\n",
    "        N = nn.functional.relu(self.fc3(N))\n",
    "        return N\n",
    "\n",
    "    def tmul(self, x, y):  #Takes (I * J * K)(K * L) -> I * J * L \n",
    "        x_shape = x.size()\n",
    "        y_shape = y.size()\n",
    "        return torch.mm(x.view(-1, x_shape[2]), y).view(-1, x_shape[1], y_shape[1])\n",
    "    \n",
    "def get_sample(training, target, choice):\n",
    "    target_vals = np.argmax(target, axis = 1)\n",
    "    ind, = np.where(target_vals == choice)\n",
    "    chosen_ind = np.random.choice(ind, 50000)\n",
    "    return training[chosen_ind], target[chosen_ind]\n",
    "\n",
    "n_targets = target.shape[1]\n",
    "samples = [get_sample(training, target, i) for i in range(n_targets)]\n",
    "trainings = [i[0] for i in samples]\n",
    "targets = [i[1] for i in samples]\n",
    "big_training = np.concatenate(trainings)\n",
    "big_target = np.concatenate(targets)\n",
    "big_training, big_target = util.shuffle_together(big_training, big_target)\n",
    "\n",
    "val_split = 0.1\n",
    "batch_size = 1000\n",
    "n_epochs = 100\n",
    "\n",
    "trainingv = Variable(torch.FloatTensor(big_training))\n",
    "targetv = Variable(torch.from_numpy(np.argmax(big_target, axis = 1)).long())  \n",
    "trainingv, valv = torch.split(trainingv, int(trainingv.size()[0] * (1 - val_split)))\n",
    "targetv, val_targetv = torch.split(targetv, int(targetv.size()[0] * (1 - val_split)))\n",
    "gnn = GraphNet(N, n_targets, params, 10)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gnn.parameters())\n",
    "loss_vals = np.zeros(n_epochs)\n",
    "acc_vals = np.zeros(n_epochs)\n",
    "for i in range(n_epochs):\n",
    "    print(\"Epoch %s\" % i)\n",
    "    for j in range(0, trainingv.size()[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        out = gnn(trainingv[j:j + batch_size].cuda())\n",
    "        l = loss(out, targetv[j:j + batch_size].cuda())\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        loss_string = \"Loss: %s\" % \"{0:.5f}\".format(l.cpu().data.numpy()[0])\n",
    "        util.printProgressBar(j + batch_size, trainingv.size()[0], \n",
    "                              prefix = \"%s [%s/%s] \" % (loss_string, \n",
    "                                                       j + batch_size, \n",
    "                                                       trainingv.size()[0]),\n",
    "                              length = 20)\n",
    "    lst = []\n",
    "    for j in torch.split(valv, 100):\n",
    "        a = gnn(j.cuda()).cpu().data.numpy()\n",
    "        lst.append(a)\n",
    "    predicted = Variable(torch.FloatTensor(np.concatenate(lst)))\n",
    "    acc_vals[i] = stats(predicted, val_targetv)\n",
    "    loss_vals[i] = l.cpu().data.numpy()[0]\n",
    "    if all(loss_vals[max(0, i - 5):i] > min(loss_vals[0:max(0, i - 5)])) and i > 5:\n",
    "        print(loss_vals, '\\n', np.diff(loss_vals))\n",
    "        break\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = GraphNet(3, 4, ['Px'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predict, target):\n",
    "    _, p_vals = torch.max(predict, 1)\n",
    "    r = torch.sum(target == p_vals.squeeze(1)).data.numpy()[0]\n",
    "    t = target.size()[0]\n",
    "    return r * 1.0 / t\n",
    "\n",
    "def stats(predict, target):\n",
    "    _, p_vals = torch.max(predict, 1)\n",
    "    t = target.cpu().data.numpy()\n",
    "    p_vals = p_vals.squeeze(1).data.numpy()\n",
    "    vals = np.unique(t)\n",
    "    for i in vals:\n",
    "        ind = np.where(t == i)\n",
    "        pv = p_vals[ind]\n",
    "        correct = sum(pv == t[ind])\n",
    "        print(\"  Target %s: %s/%s = %s%%\" % (i, correct, len(pv), correct * 100.0/len(pv)))\n",
    "    print(\"Overall: %s/%s = %s%%\" % (sum(p_vals == t), len(t), sum(p_vals == t) * 100.0/len(t)))\n",
    "    return sum(p_vals == t) * 100.0/len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n + 1)\n",
    "\n",
    "def predicted_histogram(data, \n",
    "                        target, \n",
    "                        labels = None, \n",
    "                        nbins = 10, \n",
    "                        out = None,\n",
    "                        xlabel = None,\n",
    "                        title = None\n",
    "                       ):\n",
    "    \"\"\"@params:\n",
    "        data = n x 1 array of parameter values\n",
    "        target = n x categories array of predictions\n",
    "    \"\"\"\n",
    "    target = preprocessing.normalize(target, norm = \"l1\")\n",
    "    if labels == None:\n",
    "        labels = [\"\" for i in range(target.shape[1])]\n",
    "    #1 decide bins\n",
    "    ma = np.amax(data) * 1.0\n",
    "    mi = np.amin(data)\n",
    "    bins = np.linspace(mi, ma, nbins)\n",
    "    bin_size = bins[1] - bins[0]\n",
    "    bin_locs = np.digitize(data, bins, right = True)\n",
    "    #2 set up bin x category matrix\n",
    "    #  Each M(bin, category) = Sum over particles with param in bin of category\n",
    "    M = np.array([np.sum(target[np.where(bin_locs == i)], axis = 0) \n",
    "                  for i in range(nbins)])\n",
    "    #3 plot each category/bin\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    bars = np.array([M[:, i] for i in range(M.shape[1])])\n",
    "    cmap = get_cmap(len(bars), 'viridis')\n",
    "    for i in range(len(bars)):\n",
    "        ax.bar(bins, bars[i], \n",
    "               bottom = sum(bars[:i]), \n",
    "               color = cmap(i), \n",
    "               label = labels[i],\n",
    "               width = bin_size\n",
    "              )\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "def generate_control_plots():\n",
    "    len_params = len(params)\n",
    "    path = '/bigdata/shared/HepSIM/img/n-h-hb/'\n",
    "    os.makedirs(path)\n",
    "    pred = gnn(valv)\n",
    "    d_target = np.array([util.get_list_from_num(i, length = n_targets) \n",
    "                             for i in val_targetv.cpu().data.numpy()])\n",
    "    p_target = pred.cpu().data.numpy()\n",
    "    for i in range(len(params)):\n",
    "        xlabel = params[i]\n",
    "        labels = [\"None\", \"H\", \"H + b\"]\n",
    "        data = np.mean(valv.data.numpy()[:, i, :], axis = 1)\n",
    "        predicted_histogram(data, d_target, \n",
    "                            nbins = 50, labels = labels,\n",
    "                            xlabel = xlabel, \n",
    "                            title = \"Actual Distribution\"\n",
    "                           )\n",
    "        plt.savefig(path + xlabel + \"-actual.png\", dpi = 200)\n",
    "        predicted_histogram(data, p_target, \n",
    "                            nbins = 50, labels = labels,\n",
    "                            xlabel = xlabel,\n",
    "                            title = \"Predicted Distribution\"\n",
    "                           )\n",
    "        plt.savefig(path + xlabel + \"-predicted.png\", dpi = 200)\n",
    "        plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "path = '/bigdata/shared/HepSIM/img/1ep-'\n",
    "display(Image(filename=path + 'Px-actual.png'))\n",
    "display(Image(filename=path + 'Px-predicted.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_control_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/bigdata/shared/HepSIM/np/'\n",
    "np.save(save_path + 'training-100.npy', training)\n",
    "np.save(save_path + 'target.npy', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.FloatTensor(np.concatenate(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.parents.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = util.h5_to_df(\"/bigdata/shared/HepSIM/combo/pythia8_higgs_2_combo.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.parents.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.parents == \"['Z', 'b', 't']\"].njet.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0  0  1  0  1  0\n",
       " 1  0  0  0  0  1\n",
       " 0  1  0  1  0  0\n",
       "[torch.cuda.FloatTensor of size 3x6 (GPU 0)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn.Rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
