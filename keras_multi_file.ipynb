{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['codemirror/mode/clike/clike'], function(Clike) { console.log('ROOTaaS - C++ CodeMirror module loaded'); });"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to ROOTaaS 6.06/04\n",
      "reading file\n",
      "Generate dictionary\n",
      "Assigning jet_type...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "util.py:371: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  l = np.zeros(length)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import util\n",
    "df = util.h5_to_df(\"/bigdata/shared/HepSIM/combo/pythia8_higgs_2_combo.h5\")\n",
    "params = ['Px','Py', 'Pz', 'PT', 'E', 'D0', 'DZ', 'X', 'Y',  'Z', 'T', 'count']\n",
    "training, target = util.df_to_target(df, output = None, params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sample(training, target, choice):\n",
    "    target_vals = np.argmax(target, axis = 1)\n",
    "    ind, = np.where(target_vals == choice)\n",
    "    chosen_ind = np.random.choice(ind, 30000)\n",
    "    return training[chosen_ind], target[chosen_ind]\n",
    "\n",
    "samples = [get_sample(training, target, i) for i in range(5)]\n",
    "trainings = [i[0] for i in samples]\n",
    "targets = [i[1] for i in samples]\n",
    "big_training = np.concatenate(trainings)\n",
    "big_target = np.concatenate(targets)\n",
    "big_training, big_target = util.shuffle_together(big_training, big_target)\n",
    "#big_target = big_target[:, :]\n",
    "big_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/100\n",
      "120000/120000 [==============================] - 77s - loss: 1.7206 - acc: 0.1561 - val_loss: 1.6307 - val_acc: 0.1258\n",
      "Epoch 2/100\n",
      "120000/120000 [==============================] - 76s - loss: 2.5346 - acc: 0.1425 - val_loss: 2.5015 - val_acc: 0.1558\n",
      "Epoch 3/100\n",
      "120000/120000 [==============================] - 77s - loss: 2.2369 - acc: 0.1463 - val_loss: 2.1065 - val_acc: 0.1466\n",
      "Epoch 4/100\n",
      "120000/120000 [==============================] - 77s - loss: 2.3048 - acc: 0.1353 - val_loss: 2.4987 - val_acc: 0.1453\n",
      "Epoch 5/100\n",
      "120000/120000 [==============================] - 77s - loss: 2.4379 - acc: 0.1478 - val_loss: 2.4134 - val_acc: 0.1906\n",
      "Epoch 6/100\n",
      "120000/120000 [==============================] - 77s - loss: 2.4145 - acc: 0.2005 - val_loss: 2.3058 - val_acc: 0.1996\n",
      "Epoch 7/100\n",
      "120000/120000 [==============================] - 78s - loss: 2.2725 - acc: 0.1902 - val_loss: 2.3288 - val_acc: 0.1892\n",
      "Epoch 8/100\n",
      "120000/120000 [==============================] - 78s - loss: 2.3032 - acc: 0.1888 - val_loss: 2.4002 - val_acc: 0.1795\n",
      "Epoch 9/100\n",
      "120000/120000 [==============================] - 77s - loss: 2.2396 - acc: 0.1788 - val_loss: 2.2059 - val_acc: 0.1746\n",
      "Epoch 10/100\n",
      "120000/120000 [==============================] - 77s - loss: 2.1739 - acc: 0.1799 - val_loss: 2.1401 - val_acc: 0.1771\n",
      "Epoch 11/100\n",
      "120000/120000 [==============================] - 77s - loss: 2.0666 - acc: 0.1712 - val_loss: 2.0918 - val_acc: 0.1748\n",
      "Epoch 12/100\n",
      "120000/120000 [==============================] - 77s - loss: 2.4429 - acc: 0.1720 - val_loss: 2.4139 - val_acc: 0.1654\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\n",
      "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\n",
      "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\n",
      "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\n",
      "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\n",
      "name: GeForce GTX 1080\r\n",
      "major: 6 minor: 1 memoryClockRate (GHz) 1.7335\r\n",
      "pciBusID 0000:0c:00.0\r\n",
      "Total memory: 7.92GiB\r\n",
      "Free memory: 7.81GiB\r\n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:0c:00.0)\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 9999 get requests, put_count=5156 evicted_count=1000 eviction_rate=0.193949 and unsatisfied allocation rate=0.594359\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3302 get requests, put_count=7313 evicted_count=4000 eviction_rate=0.546971 and unsatisfied allocation rate=0.000302847\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1510 get requests, put_count=3526 evicted_count=2000 eviction_rate=0.567215 and unsatisfied allocation rate=0.000662252\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 809 get requests, put_count=1832 evicted_count=1000 eviction_rate=0.545852 and unsatisfied allocation rate=0\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 13010 get requests, put_count=12413 evicted_count=5000 eviction_rate=0.402804 and unsatisfied allocation rate=0.43236\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 309 to 339\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3103 get requests, put_count=7139 evicted_count=4000 eviction_rate=0.560303 and unsatisfied allocation rate=0.000322269\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2608 get requests, put_count=5656 evicted_count=3000 eviction_rate=0.53041 and unsatisfied allocation rate=0.000383436\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2610 get requests, put_count=5668 evicted_count=3000 eviction_rate=0.529287 and unsatisfied allocation rate=0.000383142\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1550 get requests, put_count=3621 evicted_count=2000 eviction_rate=0.552334 and unsatisfied allocation rate=0.000645161\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1585 get requests, put_count=3671 evicted_count=2000 eviction_rate=0.544811 and unsatisfied allocation rate=0.000630915\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2684 get requests, put_count=5799 evicted_count=3000 eviction_rate=0.517331 and unsatisfied allocation rate=0\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2504 get requests, put_count=5644 evicted_count=3000 eviction_rate=0.531538 and unsatisfied allocation rate=0\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 728 get requests, put_count=1914 evicted_count=1000 eviction_rate=0.522466 and unsatisfied allocation rate=0\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 13487 get requests, put_count=13265 evicted_count=3000 eviction_rate=0.226159 and unsatisfied allocation rate=0.255579\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 2478 to 2725\r\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1204 get requests, put_count=2533 evicted_count=1000 eviction_rate=0.394789 and unsatisfied allocation rate=0\r\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Masking, Dense, Dropout, Activation, Reshape\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "m = Sequential()\n",
    "m.add(Masking(0, input_shape = (util.max_len, len(params))))\n",
    "m.add(GRU(200, return_sequences = True))\n",
    "m.add(GRU(5))\n",
    "m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist6 = m.fit(big_training, big_target, nb_epoch=100, verbose = 1, validation_split=0.2, batch_size = 1000,\n",
    "              callbacks=[EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min'),\n",
    "              ModelCheckpoint(filepath='simple3.h5', verbose=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = ['Px','Py', 'Pz', 'PT', 'E', 'D0', 'DZ', 'X', 'Y',  'Z', 'count']\n",
    "training, target = util.df_to_target(df, output = None, params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "ax = sns.violinplot(x = \"mom\", y = \"PT\", cut = 0, data = df_sub, scale=\"area\", gridsize = 2000)\n",
    "ax.set_ylim([0, 20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = sns.violinplot(x = 'mom', y = 'PT', cut = 0, scale = 'area', data = df.sample(20000), gridsize = 2000)\n",
    "ax.set_xticklabels([\"Other\", \"H\", \"H + b\"])\n",
    "ax.set_ylim([0, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "def show_losses( histories ):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    #plt.ylim(bottom=0)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Error by Epoch')\n",
    "    colors=[]\n",
    "    do_acc=False\n",
    "    for label,loss in histories:\n",
    "        color = tuple(np.random.random(3))\n",
    "        colors.append(color)\n",
    "        l = label\n",
    "        vl= label+\" validation\"\n",
    "        if 'acc' in loss.history:\n",
    "            l+=' (acc %2.4f)'% (loss.history['acc'][-1])\n",
    "            do_acc = True\n",
    "        if 'val_acc' in loss.history:\n",
    "            vl+=' (val acc %2.4f)'% (loss.history['val_acc'][-1])\n",
    "            do_acc = True\n",
    "        plt.plot(loss.history['loss'], label=l, color=color)\n",
    "        if 'val_loss' in loss.history:\n",
    "            plt.plot(loss.history['val_loss'], lw=2, ls='dashed', label=vl, color=color)\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(l + '-loss.png')\n",
    "    plt.show()\n",
    "    if not do_acc: return\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    for i,(label,loss) in enumerate(histories):\n",
    "        color = colors[i]\n",
    "        if 'acc' in loss.history:\n",
    "            plt.plot(loss.history['acc'][:-1], lw=2, label=label+\" accuracy\", color=color)\n",
    "        if 'val_acc' in loss.history:\n",
    "            plt.plot(loss.history['val_acc'][:-1], lw=2, ls='dashed', label=label+\" validation accuracy\", color=color)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(l + '-acc.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_losses([(\"H + b vs. H vs. not H\" , hist5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def stacked_histogram(df, param):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    vals = [df[df.mom == i][param] for i in df.mom.unique()[1:]]\n",
    "    ax.hist(vals, normed = True, stacked = True, histtype = \"stepfilled\")#, linewidth = 2)\n",
    "    #ax.set_yscale('log')\n",
    "stacked_histogram(df, 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
