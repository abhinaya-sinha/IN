{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "params = ['Px', 'Py', 'Pz', 'E', 'D0', 'DZ', 'X', 'Y', 'Z']\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_values(vals, val = 0, max_len = max_len):\n",
    "    sr, sc = vals.shape\n",
    "    if max_len - sr > 0:\n",
    "        return np.pad(vals, ((0, max_len - sr), (0, 0)), mode='constant')\n",
    "    return vals[:, :max_len, :]\n",
    "\n",
    "def print_accuracy( p, target ):\n",
    "    p_cat = np.argmax(p,axis=1)\n",
    "    test_target = np.argmax(target, axis = 1)\n",
    "    print \"Fraction of good prediction\"\n",
    "    print len(np.where( p_cat == test_target)[0])\n",
    "    print len(np.where( p_cat == test_target )[0])/float(len(p_cat)),\"%\"\n",
    "\n",
    "def accuracy(p, target):\n",
    "    p_cat = np.argmax(p,axis=1)\n",
    "    test_target = np.argmax(target, axis = 1)\n",
    "    return len(np.where( p_cat == test_target)[0])/float(len(p_cat))\n",
    "    \n",
    "def df_to_target(df, output, params = params):\n",
    "    print \"lookup\"\n",
    "    training = [df.loc[df['njet']==j][params].sort_values(['D0', 'DZ'], ascending = False) \n",
    "                    for j in df.njet.unique()]\n",
    "    print \"to numpy\"\n",
    "    training = np.array([pad_values(i.values) for i in training])\n",
    "    training_target = np.array([output for i in range(len(training))])\n",
    "    return training, training_target\n",
    "    \n",
    "def df_njet_index(df):\n",
    "    \"\"\"Combine event # and jet #\"\"\"\n",
    "    events_jets = df[['event', 'jet']].values\n",
    "    njet = np.zeros(events_jets.shape[0])\n",
    "    prev = np.array([-1, -1])\n",
    "    count = -1\n",
    "    for ind, val in enumerate(events_jets):\n",
    "        if any(prev != val):\n",
    "            count += 1\n",
    "            prev = val\n",
    "        njet[ind] = count\n",
    "    df['njet'] = njet\n",
    "    \n",
    "def h5_to_target(fname, output, params = params):\n",
    "    df = pd.read_hdf(fname)\n",
    "    df_njet_index(df)\n",
    "    return df_to_target(df, output, params)\n",
    "\n",
    "def make_test_split(training, target, test_size = 200):\n",
    "    \"\"\"Split training/target into training/target and test/target\"\"\"\n",
    "    num = training.shape[0]\n",
    "    indices = np.random.choice(range(num), test_size, replace = False)\n",
    "    test = training[indices]\n",
    "    test_target = target[indices]\n",
    "    training = np.delete(training, indices, axis = 0)\n",
    "    target = np.delete(target, indices, axis = 0)\n",
    "    return training, target, test, test_target\n",
    "\n",
    "def get_training_target_sample(training, target, sample_size):\n",
    "    indices = np.random.choice(range(training.shape[0]), sample_size, replace = False)\n",
    "    ntraining = training[indices]\n",
    "    ntarget = target[indices]\n",
    "    return ntraining, ntarget\n",
    "\n",
    "def shuffle_together(training, target):\n",
    "    p = np.random.permutation(len(training))\n",
    "    return training[p], target[p]\n",
    "\n",
    "def combine_sets(sets, sample_size = 10000):\n",
    "    \"\"\"Combine a list of (training, target, test, test_target) sets\"\"\"\n",
    "    a = min([i[0].shape[0] for i in sets])\n",
    "    sample_size = min(a, sample_size)\n",
    "    samples = [get_training_target_sample(i[0], i[1], sample_size) for i in sets]\n",
    "    ntraining = np.concatenate([i[0] for i in samples])\n",
    "    ntarget = np.concatenate([i[1] for i in samples])\n",
    "    ntest = np.concatenate([i[2] for i in sets])\n",
    "    ntest_target = np.concatenate([i[3] for i in sets])\n",
    "    ntraining, ntarget = shuffle_together(ntraining, ntarget)\n",
    "    ntest, ntest_target = shuffle_together(ntest, ntest_target)\n",
    "    return ntraining, ntarget, ntest, ntest_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup\n",
      "to numpy\n",
      "lookup\n",
      "to numpy\n"
     ]
    }
   ],
   "source": [
    "a = h5_to_target('qcd_out.h5', output = [1, 0])\n",
    "b = h5_to_target('higgs_out.h5', output = [0, 1])\n",
    "qcd = make_test_split(*a)\n",
    "higgs = make_test_split(*b)\n",
    "training, training_target, test, test_target = combine_sets([qcd, higgs], sample_size = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training using 1000 training points\n",
      "Total time: 28.8684048653\n",
      "Fraction of good prediction\n",
      "235\n",
      "0.5875 %\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Masking, Dense, Dropout, Activation, Reshape\n",
    "from keras.layers.recurrent import LSTM\n",
    "m = Sequential()\n",
    "m.add(Masking(0, input_shape = (max_len, len(params))))\n",
    "m.add(LSTM(100))\n",
    "m.add(Dense(2))\n",
    "m.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "for i in range(1000, 1001, 1000):\n",
    "    print \"Training using %s training points\" % i\n",
    "    s = time.time()\n",
    "    m.fit(training[:i], training_target[:i], nb_epoch=10, verbose = 0)\n",
    "    e = time.time()\n",
    "    print \"Total time: %s\" % (e - s)\n",
    "    print_accuracy(m.predict(test), test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.predict(test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = m.predict(test)\n",
    "for ind, t in enumerate(test_target):\n",
    "    print a[ind], t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy(m.predict(test), test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500919110.882467"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.backend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano training time: 188.917440891 \n",
    "\n",
    "Tensorflow (CPU) training time: 28.8684048653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
