{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd.variable import *\n",
    "import torch.optim as optim\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import rc\n",
    "import setGPU\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import h5py\n",
    "\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rcParams['font.size'] = 22\n",
    "rcParams['text.latex.preamble'] = [\n",
    "#       r'\\usepackage{siunitx}',   # i need upright \\micro symbols, but you need...\n",
    "#       r'\\sisetup{detect-all}',   # ...this to force siunitx to actually use your fonts\n",
    "       r'\\usepackage{helvet}',    # set the normal font here\n",
    "       r'\\usepackage{sansmath}',  # load up the sansmath so that math -> helvet\n",
    "       r'\\sansmath'               # <- tricky! -- gotta actually tell tex to use!\n",
    "]  \n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/nfshome/emoreno/IN/data/opendata/test/'\n",
    "#test_0 = np.load(save_path + 'test_features_0.npy')\n",
    "#test_0 = np.swapaxes(test_0, 1, 2)\n",
    "#training_0 = np.load(save_path + 'train_withSpectator_features_0.npy') #per jet constituents\n",
    "#training_0 = np.swapaxes(training_0, 1, 2)\n",
    "#training_2 = np.load(save_path + 'train_features_2.npy') #30 features of 60 charged particles\n",
    "#training_2 = np.swapaxes(training_2, 1, 2)\n",
    "#training_3 = np.load(save_path + 'train_features_3.npy') #14 features of 5 secondary vertices\n",
    "#training_3 = np.swapaxes(training_3, 1, 2)\n",
    "#target = np.load(save_path + 'train_truth_0.npy')\n",
    "#test_0 = np.load(save_path + 'test_0.npy')\n",
    "#test_0 = np.swapaxes(test_0, 1, 2)\n",
    "#print(test_0.shape)\n",
    "#test_1 = np.load(save_path + 'test_1.npy')\n",
    "#test_1 = np.swapaxes(test_1, 1, 2)\n",
    "\n",
    "# Load tracks dataset\n",
    "test_2 = np.load(save_path + 'test_2.npy')\n",
    "test_2 = np.swapaxes(test_2, 1, 2)\n",
    "\n",
    "# Load SV dataset\n",
    "test_3 = np.load(save_path + 'test_3.npy')\n",
    "test_3 = np.swapaxes(test_3, 1, 2)\n",
    "target_test = np.load(save_path + 'truth_0.npy')\n",
    "\n",
    "params_0 = ['fj_jetNTracks',\n",
    "          'fj_nSV',\n",
    "          'fj_tau0_trackEtaRel_0',\n",
    "          'fj_tau0_trackEtaRel_1',\n",
    "          'fj_tau0_trackEtaRel_2',\n",
    "          'fj_tau1_trackEtaRel_0',\n",
    "          'fj_tau1_trackEtaRel_1',\n",
    "          'fj_tau1_trackEtaRel_2',\n",
    "          'fj_tau_flightDistance2dSig_0',\n",
    "          'fj_tau_flightDistance2dSig_1',\n",
    "          'fj_tau_vertexDeltaR_0',\n",
    "          'fj_tau_vertexEnergyRatio_0',\n",
    "          'fj_tau_vertexEnergyRatio_1',\n",
    "          'fj_tau_vertexMass_0',\n",
    "          'fj_tau_vertexMass_1',\n",
    "          'fj_trackSip2dSigAboveBottom_0',\n",
    "          'fj_trackSip2dSigAboveBottom_1',\n",
    "          'fj_trackSip2dSigAboveCharm_0',\n",
    "          'fj_trackSipdSig_0',\n",
    "          'fj_trackSipdSig_0_0',\n",
    "          'fj_trackSipdSig_0_1',\n",
    "          'fj_trackSipdSig_1',\n",
    "          'fj_trackSipdSig_1_0',\n",
    "          'fj_trackSipdSig_1_1',\n",
    "          'fj_trackSipdSig_2',\n",
    "          'fj_trackSipdSig_3',\n",
    "          'fj_z_ratio'\n",
    "          ]\n",
    "\n",
    "params_1 = ['pfcand_ptrel',\n",
    "          'pfcand_erel',\n",
    "          'pfcand_phirel',\n",
    "          'pfcand_etarel',\n",
    "          'pfcand_deltaR',\n",
    "          'pfcand_puppiw',\n",
    "          'pfcand_drminsv',\n",
    "          'pfcand_drsubjet1',\n",
    "          'pfcand_drsubjet2',\n",
    "          'pfcand_hcalFrac'\n",
    "         ]\n",
    "\n",
    "params_2 = ['track_ptrel',     \n",
    "          'track_erel',     \n",
    "          'track_phirel',     \n",
    "          'track_etarel',     \n",
    "          'track_deltaR',\n",
    "          'track_drminsv',     \n",
    "          'track_drsubjet1',     \n",
    "          'track_drsubjet2',\n",
    "          'track_dz',     \n",
    "          'track_dzsig',     \n",
    "          'track_dxy',     \n",
    "          'track_dxysig',     \n",
    "          'track_normchi2',     \n",
    "          'track_quality',     \n",
    "          'track_dptdpt',     \n",
    "          'track_detadeta',     \n",
    "          'track_dphidphi',     \n",
    "          'track_dxydxy',     \n",
    "          'track_dzdz',     \n",
    "          'track_dxydz',     \n",
    "          'track_dphidxy',     \n",
    "          'track_dlambdadz',     \n",
    "          'trackBTag_EtaRel',     \n",
    "          'trackBTag_PtRatio',     \n",
    "          'trackBTag_PParRatio',     \n",
    "          'trackBTag_Sip2dVal',     \n",
    "          'trackBTag_Sip2dSig',     \n",
    "          'trackBTag_Sip3dVal',     \n",
    "          'trackBTag_Sip3dSig',     \n",
    "          'trackBTag_JetDistVal'\n",
    "         ]\n",
    "\n",
    "params_3 = ['sv_ptrel',\n",
    "          'sv_erel',\n",
    "          'sv_phirel',\n",
    "          'sv_etarel',\n",
    "          'sv_deltaR',\n",
    "          'sv_pt',\n",
    "          'sv_mass',\n",
    "          'sv_ntracks',\n",
    "          'sv_normchi2',\n",
    "          'sv_dxy',\n",
    "          'sv_dxysig',\n",
    "          'sv_d3d',\n",
    "          'sv_d3dsig',\n",
    "          'sv_costhetasvpv'\n",
    "         ]\n",
    "\n",
    "test_sv = test_3\n",
    "test = test_2\n",
    "N = test.shape[2]\n",
    "params = params_2\n",
    "params_sv = params_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn import utils\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, n_constituents, n_targets, params, hidden):\n",
    "        super(GraphNet, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        self.P = len(params)\n",
    "        self.N = n_constituents\n",
    "        self.S = test_sv.shape[1]\n",
    "        self.Nv = test_sv.shape[2]\n",
    "        self.Nr = self.N * (self.N - 1)\n",
    "        self.Dr = 0\n",
    "        self.De = 5\n",
    "        self.Dx = 0\n",
    "        self.Do = 6\n",
    "        self.n_targets = n_targets\n",
    "        self.assign_matrices()\n",
    "        self.assign_matrices_SV()\n",
    "        #self.switch = switch\n",
    "        \n",
    "        self.Ra = torch.ones(self.Dr, self.Nr)\n",
    "        self.fr1 = nn.Linear(2 * self.P + self.Dr, hidden).cuda()\n",
    "        self.fr1_sv = nn.Linear(self.S + self.P + self.Dr, hidden).cuda()\n",
    "        self.fr2 = nn.Linear(hidden, hidden/2).cuda()\n",
    "        self.fr3 = nn.Linear(hidden/2, self.De).cuda()\n",
    "        self.fo1 = nn.Linear(self.P + self.Dx + (2 * self.De), hidden).cuda()\n",
    "        self.fo2 = nn.Linear(hidden, hidden/2).cuda()\n",
    "        self.fo3 = nn.Linear(hidden/2, self.Do).cuda()\n",
    "        self.fc1 = nn.Linear(self.Do * self.N, hidden).cuda()\n",
    "        self.fc2 = nn.Linear(hidden, hidden/2).cuda()\n",
    "        self.fc3 = nn.Linear(hidden/2, self.n_targets).cuda()\n",
    "        self.fc_fixed = nn.Linear(self.Do, self.n_targets).cuda()\n",
    "        #self.gru = nn.GRU(input_size = self.Do, hidden_size = 20, bidirectional = False).cuda()\n",
    "            \n",
    "    def assign_matrices(self):\n",
    "        self.Rr = torch.zeros(self.N, self.Nr)\n",
    "        self.Rs = torch.zeros(self.N, self.Nr)\n",
    "        receiver_sender_list = [i for i in itertools.product(range(self.N), range(self.N)) if i[0]!=i[1]]\n",
    "        for i, (r, s) in enumerate(receiver_sender_list):\n",
    "            self.Rr[r, i] = 1\n",
    "            self.Rs[s, i] = 1\n",
    "        self.Rr = (self.Rr).cuda()\n",
    "        self.Rs = (self.Rs).cuda()\n",
    "    \n",
    "    def assign_matrices_SV(self):\n",
    "        self.Rk = torch.zeros(self.N, self.Nr)\n",
    "        self.Rv = torch.zeros(self.Nv, self.Nr)\n",
    "        receiver_sender_list = [i for i in itertools.product(range(self.N), range(self.Nv)) if i[0]!=i[1]]\n",
    "        for i, (k, v) in enumerate(receiver_sender_list):\n",
    "            self.Rk[k, i] = 1\n",
    "            self.Rv[v, i] = 1\n",
    "        self.Rk = (self.Rk).cuda()\n",
    "        self.Rv = (self.Rv).cuda()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        ###PF Candidate - PF Candidate###\n",
    "        Orr = self.tmul(x, self.Rr)\n",
    "        Ors = self.tmul(x, self.Rs)\n",
    "        B = torch.cat([Orr, Ors], 1)\n",
    "        ### First MLP ###\n",
    "        B = torch.transpose(B, 1, 2).contiguous()\n",
    "        B = nn.functional.relu(self.fr1(B.view(-1, 2 * self.P + self.Dr)))\n",
    "        B = nn.functional.relu(self.fr2(B))\n",
    "        E = nn.functional.relu(self.fr3(B).view(-1, self.Nr, self.De))\n",
    "        del B\n",
    "        E = torch.transpose(E, 1, 2).contiguous()\n",
    "        Ebar = self.tmul(E, torch.transpose(self.Rr, 0, 1).contiguous())\n",
    "        del E\n",
    "        \n",
    "        ####Secondary Vertex - PF Candidate### \n",
    "        Ork = self.tmul(x, self.Rk)\n",
    "        Orv = self.tmul(y, self.Rv)\n",
    "        B = torch.cat([Ork, Orv], 1)\n",
    "        ### First MLP ###\n",
    "        B = torch.transpose(B, 1, 2).contiguous()\n",
    "        B = nn.functional.relu(self.fr1_sv(B.view(-1, self.S + self.P + self.Dr)))\n",
    "        B = nn.functional.relu(self.fr2(B))\n",
    "        E = nn.functional.relu(self.fr3(B).view(-1, self.Nr, self.De))\n",
    "        del B\n",
    "        E = torch.transpose(E, 1, 2).contiguous()\n",
    "        Ebar_sv = self.tmul(E, torch.transpose(self.Rr, 0, 1).contiguous())\n",
    "        del E\n",
    "\n",
    "        ####Final output matrix###\n",
    "        C = torch.cat([x, Ebar], 1)\n",
    "        del Ebar\n",
    "        C = torch.cat([C, Ebar_sv], 1)\n",
    "        del Ebar_sv\n",
    "        C = torch.transpose(C, 1, 2).contiguous()\n",
    "        ### Second MLP ###\n",
    "        C = nn.functional.relu(self.fo1(C.view(-1, self.P + self.Dx + (2 * self.De))))\n",
    "        C = nn.functional.relu(self.fo2(C))\n",
    "        O = nn.functional.relu(self.fo3(C).view(-1, self.N, self.Do))\n",
    "        #Taking the mean/sum of each column\n",
    "        #N = torch.mean(O, dim=1)\n",
    "        N = torch.sum(O, dim=1)\n",
    "        del C\n",
    "        ### Classification MLP ###\n",
    "        #N = nn.functional.relu(self.fc1(O.view(-1, self.Do * self.N)))\n",
    "        del O\n",
    "        #N = nn.functional.relu(self.fc2(N))\n",
    "        #N = nn.functional.relu(self.fc3(N))\n",
    "        N = nn.functional.relu(self.fc_fixed(N))\n",
    "        #P = np.array(N.data.cpu().numpy())\n",
    "        #N = np.zeros((128, 1, 6))\n",
    "        #for i in range(batch_size):\n",
    "        #    N[i] = np.array(np.split(P[i], self.Do))\n",
    "        #    N[1] = [P[i]]\n",
    "        #N, hn = self.gru(torch.tensor(N).cuda())\n",
    "        #print((N).shape)\n",
    "        return N \n",
    "            \n",
    "    def tmul(self, x, y):  #Takes (I * J * K)(K * L) -> I * J * L \n",
    "        x_shape = x.size()\n",
    "        y_shape = y.size()\n",
    "        return torch.mm(x.view(-1, x_shape[2]), y).view(-1, x_shape[1], y_shape[1])\n",
    "\n",
    "#n_targets = test.shape[1]\n",
    "n_targets = 2\n",
    "N = 60\n",
    "gnn = GraphNet(N, n_targets, params, 15)\n",
    "#gnn.load_state_dict(torch.load('IN_opendata_V2'))\n",
    "\n",
    "def get_sample(training1, training2, target, choice):\n",
    "    target_vals = np.argmax(target, axis = 1)\n",
    "    ind, = np.where(target_vals == choice)\n",
    "    chosen_ind = np.random.choice(ind, 300000)\n",
    "    return training1[chosen_ind], training2[chosen_ind], target[chosen_ind]\n",
    "\n",
    "def get_sample_train(training1, training2, target, choice):\n",
    "    target_vals = np.argmax(target, axis = 1)\n",
    "    ind, = np.where(target_vals == choice)\n",
    "    chosen_ind = ind\n",
    "    #chosen_ind = np.random.choice(ind, 200000)\n",
    "    return training1[chosen_ind], training2[chosen_ind], target[chosen_ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions on test dataset \n",
    "prediction = np.load('/nfshome/emoreno/IN/avikar-surf2017/opendata/IN_out_Run2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-37d18ed41448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msoftmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetv_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \"\"\"\n\u001b[1;32m    533\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 534\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    316\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    317\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multilabel-indicator format is not supported"
     ]
    }
   ],
   "source": [
    "# Create ROC Plot\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(target_test, prediction)\n",
    "auc = roc_auc_score(target_test, prediction)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.set_xlim(0,1)\n",
    "ax.set_ylim(0.001,1)\n",
    "sig=[\"Hbb\"]\n",
    "bkg=[\"QCD\"]\n",
    "eraText=r'2016 (13 TeV)'\n",
    "xlab = '{} \\\\rightarrow {}'.format(sig[0][0], sig[0][-2]+'\\\\bar{'+sig[0][-1]+'}') \n",
    "ax.set_xlabel(r'Tagging efficiency ($\\mathrm{}$)'.format('{'+xlab+'}'), ha='right', x=1.0)\n",
    "ylab = ['{} \\\\rightarrow {}'.format(l[0], l[-2]+'\\\\bar{'+l[-1]+'}') if l[0][0] in [\"H\", \"Z\", \"g\"] else l for l in bkg ]\n",
    "ax.set_ylabel(r'Mistagging rate ($\\mathrm{}$)'.format(\"{\"+\", \".join(ylab)+\"}\"), ha='right', y=1.0)\n",
    "leg = ax.legend(borderpad=1, frameon=False, loc=2, fontsize=16,\n",
    "            title = \"\"+str(int(round((min(frame.fj_pt)))))+\" $\\mathrm{<\\ jet\\ p_T\\ <}$ \"+str(int(round((max(frame.fj_pt)))))+\" GeV\" \\\n",
    "          + \"\\n \"+str(int(round((min(frame.fj_sdmass)))))+\" $\\mathrm{<\\ jet\\ m_{sd}\\ <}$ \"+str(int(round((max(frame.fj_sdmass)))))+\" GeV\"\n",
    "                       )\n",
    "#fpr_DeepDoubleB = np.load('fpr_DDB_opendata.npy')\n",
    "#tpr_DeepDoubleB = np.load('tpr_DDB_opendata.npy')\n",
    "#plt.figure(figsize=(12,10), dpi = 200)\n",
    "lw = 2\n",
    "ax.plot(tpr, fpr, color='darkorange',\n",
    "         lw=lw, label='Interaction Network (area = %0.3f)' % auc)\n",
    "#ax.plot(tpr_DeepDoubleB, fpr_DeepDoubleB, color='navy', lw=lw, label='DeepDoubleB (area = 0.955)')\n",
    "ax.xaxis.set_major_locator(plticker.MultipleLocator(base=0.1))\n",
    "ax.xaxis.set_minor_locator(plticker.MultipleLocator(base=0.02))\n",
    "ax.tick_params(direction='in', axis='both', which='major', labelsize=15, length=12 )\n",
    "ax.tick_params(direction='in', axis='both', which='minor' , length=6)\n",
    "ax.xaxis.set_ticks_position('both')\n",
    "ax.yaxis.set_ticks_position('both')    \n",
    "ax.semilogy()\n",
    "ax.grid(which='minor', alpha=0.5, axis='y', linestyle='dotted')\n",
    "ax.grid(which='major', alpha=0.9, linestyle='dotted')\n",
    "ax.annotate(eraText, xy=(0.80, 1.1), fontname='Helvetica', ha='left',\n",
    "            bbox={'facecolor':'white', 'edgecolor':'white', 'alpha':0, 'pad':13}, annotation_clip=False)\n",
    "ax.annotate('$\\mathbf{CMS}$', xy=(0.01, 1.1), fontname='Helvetica', fontsize=24, fontweight='bold', ha='left',\n",
    "            bbox={'facecolor':'white', 'edgecolor':'white', 'alpha':0, 'pad':13}, annotation_clip=False)\n",
    "ax.annotate('$Simulation\\ Preliminary$', xy=(0.115, 1.1), fontsize=18, fontstyle='italic', ha='left',\n",
    "            annotation_clip=False)\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "f.show()\n",
    "f.savefig('ROC_curve_opendata_2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pileup vs Efficiency Plot\n",
    "import bisect\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import itertools\n",
    "from sklearn import utils\n",
    "\n",
    "NBINS= 10 # number of bins for loss function\n",
    "MMAX = 40. # max value\n",
    "MMIN = 0. # min value\n",
    "binWidth = (MMAX - MMIN) / NBINS\n",
    "datapoints = 250000\n",
    "OHE_pv = []\n",
    "auc_array = []\n",
    "cuts = [0.05, 0.1, 0.15, 0.25, 0.5]\n",
    "pileup = [[],[],[],[],[]]\n",
    "\n",
    "for i in range(NBINS): \n",
    "    OHE_pv.append([])\n",
    "    \n",
    "# One hot encode data according to pileup bins\n",
    "for i in range(datapoints):\n",
    "    if np.sum(sum(test_3[i][7])) >= MMAX: \n",
    "        OHE_pv[-1].append(i)\n",
    "    elif np.sum(sum(test_3[i][7])) <= MMIN: \n",
    "        OHE_pv[0].append(i)\n",
    "    else:\n",
    "        OHE_pv[int((np.sum(test_3[i][7]) - MMIN)/binWidth)].append(i)\n",
    "\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "n_targets = target_test.shape[1]\n",
    "\n",
    "def get_sample(training1, training2, target, choice):\n",
    "    target_vals = np.argmax(target, axis = 1)\n",
    "    ind, = np.where(target_vals == choice)\n",
    "    chosen_ind = np.random.choice(ind, datapoints)\n",
    "    return training1[chosen_ind], training2[chosen_ind], target[chosen_ind]\n",
    "\n",
    "for i in range(NBINS): \n",
    "    training_temp = test[OHE_pv[i]]\n",
    "    training_sv_temp = test_sv[OHE_pv[i]]\n",
    "    target_temp = target_test[OHE_pv[i]]\n",
    "    \n",
    "    samples = [get_sample(training_temp, training_sv_temp, target_temp, i) for i in range(n_targets)]\n",
    "    trainings = [i[0] for i in samples]\n",
    "    trainings_sv = [i[1] for i in samples]\n",
    "    targets = [i[2] for i in samples]\n",
    "    \n",
    "    print(np.array(trainings).shape)\n",
    "    big_training = np.concatenate(trainings)\n",
    "    big_training_sv = np.concatenate(trainings_sv)\n",
    "    big_target = np.concatenate(targets)\n",
    "    big_training, big_training_sv, big_target = utils.shuffle(big_training, big_training_sv, big_target)\n",
    "\n",
    "    val_split = 0.1\n",
    "    batch_size =128\n",
    "    n_epochs = 250\n",
    "    print(big_training[0][0][0])\n",
    "    trainingv = (torch.FloatTensor(big_training)).cuda()\n",
    "    trainingv_sv = (torch.FloatTensor(big_training_sv)).cuda()\n",
    "    targetv = (torch.from_numpy(np.argmax(big_target, axis = 1)).long()).cuda()\n",
    "    trainingv, valv = torch.split(trainingv, int(trainingv.size()[0] * (1 - val_split)))\n",
    "    trainingv_sv, valv_sv = torch.split(trainingv_sv, int(trainingv_sv.size()[0] * (1 - val_split)))\n",
    "    targetv, val_targetv = torch.split(targetv, int(targetv.size()[0] * (1 - val_split)))\n",
    "    samples_random = np.random.choice(range(len(trainingv)), valv.size()[0]/100)\n",
    "    out = np.array([])\n",
    "    prediction = np.array([])\n",
    "    for j in range(0, trainingv.size()[0], batch_size):\n",
    "        out_test = softmax(gnn(trainingv[j:j + batch_size].cuda(), trainingv_sv[j:j + batch_size].cuda()))\n",
    "        out_test = out_test.cpu().data.numpy()\n",
    "        #print(out_test)\n",
    "        for i in range(len(out_test)):\n",
    "            if (out_test[i][0] > out_test[i][1]): \n",
    "                prediction = np.append(prediction, out_test[i][0])\n",
    "                out = np.append(out, 0)\n",
    "            else: \n",
    "                prediction = np.append(prediction, out_test[i][1])\n",
    "                out = np.append(out, 1)\n",
    "\n",
    "    for i in range(prediction.size): \n",
    "        if out[i] == 0: \n",
    "            prediction[i] = 1.0 - prediction[i]\n",
    "            \n",
    "    fpr, tpr, thresholds = roc_curve(targetv.cpu().data.numpy(), prediction)\n",
    "    auc_array.append(roc_auc_score(targetv.cpu().data.numpy(), prediction))\n",
    "    entry = 0\n",
    "    #print(thresholds)\n",
    "    \n",
    "    events_above_min_bound = []\n",
    "    for cut in cuts: \n",
    "        entry = bisect.bisect(fpr, cut)\n",
    "        min_bound = thresholds[entry]\n",
    "        count = 0\n",
    "        for n in range(prediction.shape[0]):\n",
    "            if prediction[n] > min_bound:\n",
    "                count += 1\n",
    "        events_above_min_bound.append(count)\n",
    "    for p in range(len(cuts)):\n",
    "        print(prediction.shape[0])\n",
    "        print(events_above_min_bound[p])\n",
    "        pileup[p].append((1./prediction.shape[0])* events_above_min_bound[p])\n",
    "\n",
    "\n",
    "bins = []\n",
    "for i in range(len(pileup[0])):\n",
    "    bins.append(MMIN + i * binWidth)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.set_xlim(0,50)\n",
    "ax.set_ylim(0,1)\n",
    "sig=[\"Hbb\"]\n",
    "bkg=[\"QCD\"]\n",
    "eraText=r'2016 (13 TeV)'\n",
    "ylab = '{} \\\\rightarrow {}'.format(sig[0][0], sig[0][-2]+'\\\\bar{'+sig[0][-1]+'}') \n",
    "ax.set_ylabel(r'Tagging efficiency ($\\mathrm{}$)'.format('{'+ylab+'}'), ha='right', x=1.0)\n",
    "ax.set_ylabel(r'Number of Event Vertices (Pileup)', ha='right', y=1.0)\n",
    "#plt.figure(figsize=(12,10), dpi = 200)\n",
    "lw = 2\n",
    "ax.plot(bins, pileup[0], label = '1% Mistag')\n",
    "ax.plot(bins, pileup[1], label = '5% Mistag')\n",
    "ax.plot(bins, pileup[2], label = '10% Mistag')\n",
    "ax.plot(bins, pileup[3], label = '25% Mistag')\n",
    "ax.plot(bins, pileup[4], label = '50% Mistag')\n",
    "ax.xaxis.set_major_locator(plticker.MultipleLocator(base=0.1))\n",
    "ax.xaxis.set_minor_locator(plticker.MultipleLocator(base=0.02))\n",
    "ax.tick_params(direction='in', axis='both', which='major', labelsize=15, length=12 )\n",
    "ax.tick_params(direction='in', axis='both', which='minor' , length=6)\n",
    "#ax.xaxis.set_ticks_position('both')\n",
    "#x.yaxis.set_ticks_position('both')    \n",
    "#ax.semilogy()\n",
    "ax.grid(which='minor', alpha=0.5, axis='y', linestyle='dotted')\n",
    "ax.grid(which='major', alpha=0.9, linestyle='dotted')\n",
    "ax.annotate(eraText, xy=(0.80, 1.1), fontname='Helvetica', ha='left',\n",
    "            bbox={'facecolor':'white', 'edgecolor':'white', 'alpha':0, 'pad':13}, annotation_clip=False)\n",
    "ax.annotate('$\\mathbf{CMS}$', xy=(0.01, 1.1), fontname='Helvetica', fontsize=24, fontweight='bold', ha='left',\n",
    "            bbox={'facecolor':'white', 'edgecolor':'white', 'alpha':0, 'pad':13}, annotation_clip=False)\n",
    "ax.annotate('$Simulation\\ Opendata$', xy=(0.115, 1.1), fontsize=18, fontstyle='italic', ha='left',\n",
    "            annotation_clip=False)    \n",
    "ax.show()    \n",
    "\n",
    "plt.savefig('pileup_vs_efficiency_opendata')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
